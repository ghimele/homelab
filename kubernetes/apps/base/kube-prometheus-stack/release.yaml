---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  chart:
    spec:
      chart: kube-prometheus-stack
      version: '77.12.0'
      reconcileStrategy: ChartVersion
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
  install:
    createNamespace: true
    crds: Skip
  upgrade:
    crds: Skip
  values:
    fullnameOverride: ''

    crds:
      enabled: false

    # defaultRules:
    #   rules:
    #     etcd: false
    #     kubeApiserverBurnrate: false
    #     kubeApiserverHistogram: false
    #     kubeApiserverSlos: false
    #     kubeProxy: false
    #     kubeScheduler: false

    # alertmanager:
    #   config:
    #     inhibit_rules:
    #       - source_matchers:
    #           - 'severity = critical'
    #         target_matchers:
    #           - 'severity =~ warning|info'
    #         equal:
    #           - 'namespace'
    #           - 'alertname'
    #       - source_matchers:
    #           - 'severity = warning'
    #         target_matchers:
    #           - 'severity = info'
    #         equal:
    #           - 'namespace'
    #           - 'alertname'
    #       - source_matchers:
    #           - 'alertname = InfoInhibitor'
    #         target_matchers:
    #           - 'severity = info'
    #         equal:
    #           - 'namespace'
    #     route:
    #       group_by: ['namespace']
    #       receiver: discord
    #       routes:
    #         - receiver: nowhere
    #           matchers:
    #             - alertname =~ "InfoInhibitor|Watchdog"
    #     receivers:
    #       - name: nowhere
    #       - name: discord
    #         discord_configs:
    #           - webhook_url: ${ALERTMANAGER_DISCORD_URL}
    #             title: >-
    #               {{ template "discord.iske.title" . }}
    #             message: >-
    #               {{ template "discord.iske.message" . }}
    #             send_resolved: true
    #     templates:
    #       - /etc/alertmanager/config/*.tmpl
    #   templateFiles:
    #     discord.tmpl: |-
    #       {{ define "discord.iske.title" }}
    #       [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }}{{ end }}
    #       {{ define "discord.iske.message" }}
    #       {{ range $i, $e := .Alerts -}}
    #       {{ if $i }}———{{ end }}
    #       {{ if .Labels.severity }}`{{ .Labels.severity }}`{{ end }}

    #       {{ if and (eq .Status "resolved") .Annotations.resolved -}}
    #       *Resolved*
    #       {{ .Annotations.resolved }}
    #       {{- else -}}
    #       *Description*
    #       {{ .Annotations.description }}
    #       {{- end }}

    #       {{ if not .Annotations.minimal -}}
    #       *Labels*
    #       {{- range .Labels.SortedPairs }}
    #       • {{ .Name }}: `{{ .Value }}`
    #       {{- end }}
    #       {{- end }}
    #       {{ end }}{{ end }}
    #   serviceMonitor:
    #     relabelings:
    #       - sourceLabels: [__meta_kubernetes_pod_node_name]
    #         separator: ;
    #         regex: ^(.*)$
    #         targetLabel: nodename
    #         replacement: $1
    #         action: replace
    #   alertmanagerSpec:
    #     logLevel: info  # before: warn
    #     externalUrl: https://${HOST_ALERTS}.${DOMAIN}
    #     storage:
    #       volumeClaimTemplate:
    #         spec:
    #           storageClassName: local-path
    #           accessModes:
    #             - ReadWriteOnce
    #           resources:
    #             requests:
    #               storage: 50Gi

    grafana:
      fullnameOverride: grafana
      defaultDashboardsEnabled: false
      defaultDashboardsTimezone: ${TIMEZONE}
      adminUser: ${GRAFANA_USERNAME}
      adminPassword: ${GRAFANA_PASSWORD}
      plugins:
        - grafana-piechart-panel
      dashboardProviders:
        dashboardproviders.yaml:
          apiVersion: 1
          providers:
            - type: file
              name: Cluster
              folder: Cluster
              editable: true
              allowUiUpdates: true
              disableDeletion: false
              options:
                path: /tmp/dashboards/Cluster
                foldersFromFilesStructure: true
            - type: file
              name: Network
              folder: Network
              editable: true
              allowUiUpdates: true
              disableDeletion: false
              options:
                path: /tmp/dashboards/Network
                foldersFromFilesStructure: true
            - type: file
              name: Storage
              folder: Storage
              editable: true
              allowUiUpdates: true
              disableDeletion: false
              options:
                path: /tmp/dashboards/Storage
                foldersFromFilesStructure: true
            - type: file
              name: Home
              folder: Home
              editable: true
              allowUiUpdates: true
              disableDeletion: false
              options:
                path: /tmp/dashboards/Home
                foldersFromFilesStructure: true
            - type: file
              name: External
              folder: External
              editable: true
              allowUiUpdates: true
              disableDeletion: false
              options:
                path: /tmp/dashboards/External
                foldersFromFilesStructure: true
      grafana.ini:
        server:
          domain: ${HOST_GRAFANA}.${DOMAIN}
          root_url: https://${HOST_GRAFANA}.${DOMAIN}
          serve_from_sub_path: false
          enable_gzip: true
        auth.github:
          enabled: true
          allow_sign_up: true
          scopes: user:email,read:org
          auth_url: https://github.com/login/oauth/authorize
          token_url: https://github.com/login/oauth/access_token
          api_url: https://api.github.com/user
          client_id: ${GRAFANA_GIHUB_CLIENTID}
          client_secret: ${GRAFANA_GITHUB_CLIENTSECRET}
          allowed_domains: ghimele.com github.com outlook.com
          role_attribute_path: "[login=='${EMAIL}'][0] && 'Admin' || 'Viewer'"
          skip_org_role_sync: true
        log:
          level: warn
        users:
          allow_sign_up: false
          auto_assign_org: true
          auto_assign_org_id: 1
          auto_assign_org_role: Admin
        auth:
          disable_signout_menu: true
        auth.proxy:
          enabled: true
          header_name: Remote-User
          header_property: username
          headers: 'Name:Remote-Name Email:Remote-Email Groups:Remote-Groups'
          auto_sign_up: false
          enable_login_token: true
          sync_ttl: 60
        # remote_cache:
        #   type: redis
        #   connstr: addr=redis.redis.svc.cluster.local:6379
        analytics:
          reporting_enabled: false
          check_for_updates: true
      sidecar:
        logLevel: WARN
        dashboards:
          enabled: true
          searchNamespace: ALL
          label: grafana-dashboard
          labelValue: 'true'
          provider:
            foldersFromFilesStructure: true
        datasources:
          enabled: true
          searchNamespace: ALL
          label: grafana-datasource
          labelValue: 'true'
      serviceMonitor:
        relabelings:
          - sourceLabels: [__meta_kubernetes_pod_node_name]
            separator: ;
            regex: ^(.*)$
            targetLabel: nodename
            replacement: $1
            action: replace
      assertNoLeakedSecrets: false

    kubeControllerManager:
      enabled: false

    coreDns:
      serviceMonitor:
        relabelings:
          - sourceLabels: [__meta_kubernetes_pod_node_name]
            separator: ;
            regex: ^(.*)$
            targetLabel: nodename
            replacement: $1
            action: replace

    kubeEtcd:
      enabled: false

    kubeScheduler:
      enabled: false

    kubeProxy:
      enabled: false

    kube-state-metrics:
      fullnameOverride: kube-state-metrics
      prometheus:
        monitor:
          relabelings:
            - sourceLabels: [__meta_kubernetes_pod_node_name]
              separator: ;
              regex: ^(.*)$
              targetLabel: nodename
              replacement: $1
              action: replace

    prometheus-node-exporter:
      fullnameOverride: prometheus-node-exporter
      extraArgs:
        - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
        - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
        - --no-collector.nvme
      prometheus:
        monitor:
          relabelings:
            - sourceLabels: [__meta_kubernetes_pod_node_name]
              separator: ;
              regex: ^(.*)$
              targetLabel: nodename
              replacement: $1
              action: replace

    prometheus:
      ## Resource limits & requests
      resources:
        requests:
          memory: 500Mi
        limits:
          memory: 800Mi
      prometheusSpec:
        externalUrl: https://${HOST_PROMETHEUS}.${DOMAIN}
        # TODO: implement label for selection, enable all service monitors for now
        serviceMonitorSelector: {}
        serviceMonitorSelectorNilUsesHelmValues: false
        serviceMonitorNamespaceSelector: {}
        # TODO: implement label for selection, enable all pod monitors for now
        podMonitorSelector: {}
        podMonitorSelectorNilUsesHelmValues: false
        podMonitorNamespaceSelector: {}
        retention: 2w
        replicas: 1
        logLevel: info  # before: warn
        ruleNamespaceSelector: {}  # Add a namespace if you want Prometheus to identify rules created in specific namespaces. Leave {} to detect rules from any namespace.
        ruleSelector: {}  # Add a label if you want Prometheus to detect rules with a specific selector. Leave {} to detect rules with any label.
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: longhorn
              accessModes:
                - ReadWriteOnce
              resources:
                requests:
                  storage: 40Gi
        additionalScrapeConfigs:
          - job_name: unraid
            scheme: http
            scrape_interval: 60s
            static_configs:
              - targets: ['${HOST_OCEANO}.${DOMAIN}:9100']
          - job_name: pfsense
            scheme: http
            scrape_interval: 60s
            static_configs:
              - targets: ['${HOST_PFSENSE}.${DOMAIN}:9100']
          - job_name: 'uptime-kuma'
            scrape_interval: 60s
            scheme: http
            metrics_path: '/metrics'
            static_configs:
              - targets: ['${UPTIMEKUMA_SERVICE}.uptime-kuma.svc.cluster.local:3001']
            basic_auth:  # Only needed if authentication is enabled (default)
              username: ${UPTIMEKUMA_USERNAME}
              password: ${UPTIMEKUMA_PASSWORD}
          - job_name: 'longhorn'
            scrape_interval: 60s
            scheme: http
            metrics_path: '/metrics'
            static_configs:
              - targets: ['longhorn-backend.longhorn-system.svc.cluster.local:9500']
  interval: 10m0s
